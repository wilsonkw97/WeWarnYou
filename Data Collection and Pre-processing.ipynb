{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218ac6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV into dataframe\n",
    "df = pd.read_csv ('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15d9ecf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d297dda",
   "metadata": {},
   "source": [
    "## Most mentioned word in Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ace74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Reference : https://malaya.readthedocs.io/en/latest/Api.html#module-malaya.preprocessing\n",
    "import malaya\n",
    "\n",
    "tokenizer = malaya.preprocessing.Tokenizer(hashtags= False)\n",
    "extracbas = malaya.stem.deep_model()\n",
    "tweetlist = []\n",
    "\n",
    "for tweet in df['tweet_text']:\n",
    "    tkn = tokenizer.tokenize(tweet)\n",
    "    for t in tkn:\n",
    "        tkn = malaya.preprocessing.unpack_english_contractions(t)\n",
    "        basetkn = extracbas.stem(tkn,beam_search= False)\n",
    "    tweetlist.append(basetkn)\n",
    "\n",
    "tweetlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a17fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Custom Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "new_words = [\"co\",\"http\",\"di\",\"yang\",\"dan\",\"amp\",\"ini\", \"untuk\", \"n\", \"ni\", \"ada\", \"kami\", \"yg\", \"ke\", \"1\", \"2\", \"nak\", \"daruratbanjir\", \"3\", \"lagi\", \"tak\", \"kita\"]\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words = stop_words.union(set(new_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54e7178",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function to lemmatise data and add stop word\n",
    "\n",
    "import nltk\n",
    "def cleanData(raw_text):    \n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    from nltk.tokenize import RegexpTokenizer\n",
    "    from nltk.stem.wordnet import WordNetLemmatizer\n",
    "    \n",
    "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    words = tokenizer.tokenize(raw_text)\n",
    "\n",
    "    wordsFiltered=[]\n",
    "    for word in words:\n",
    "        if word.lower() not in stop_words:\n",
    "            wordsFiltered.append(word)\n",
    "    \n",
    "    lem = WordNetLemmatizer()\n",
    "    wordsLemmatized=[]\n",
    "    #Lemmatisation\n",
    "    for word in wordsFiltered:\n",
    "        wordsLemmatized.append(lem.lemmatize(word))\n",
    "    \n",
    "#   Convert to lowercase\n",
    "    str=''\n",
    "    for w in wordsLemmatized:\n",
    "        str = str+' '+w.lower()\n",
    "    return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80a6421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe stopwords and add to new_words\n",
    "import pandas\n",
    "\n",
    "df_word = df.apply(lambda row:cleanData(row['tweet_text']), axis = 1) # apply function to each tweet_t\n",
    "freq = pandas.Series(''.join(df_word).split()).value_counts()[0:40]\n",
    "print(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957e1129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Wordcloud and Save\n",
    "\n",
    "import os\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS,ImageColorGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#used to convert data element into list\n",
    "abstract = df_word.values.tolist() \n",
    "\n",
    "# Create wordcloud\n",
    "wordcloud = WordCloud(background_color='white', stopwords=stop_words, max_words=100,max_font_size=50, random_state=42).generate(str(abstract))\n",
    "\n",
    "# Display the generated image:\n",
    "plt.figure(figsize=(10,10)) #inches\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Save wordcloud to django static folder\n",
    "path = os.getcwd() + r\"\\WeWarnYou-dashboard\\apps\\static\\assets\\wc-word.png\"\n",
    "wordcloud.to_file(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4e28fa",
   "metadata": {},
   "source": [
    "## Most mentioned city in Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91ceb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty bracket city\n",
    "df_city = df[df.city != \"[]\"]\n",
    "\n",
    "# Remove empty value city\n",
    "df_city = df_city.dropna(subset=['city'])\n",
    "\n",
    "df_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae34823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning city data from \"['Putrajaya']\" become \"Putrajaya\" & Add to an empty wc_city list\n",
    "\n",
    "import re\n",
    "\n",
    "wc_city_list = []\n",
    "characters_to_remove = \"\\[\\]\\'\"\n",
    "pattern = \"[\" + characters_to_remove + \"]\"\n",
    "\n",
    "for city in df_city['city']:\n",
    "    wc_city_list.extend(re.sub(pattern, \"\", city).split(','))\n",
    "\n",
    "print(wc_city_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201d2198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "wc_city = (\" \").join(wc_city_list)\n",
    "wordcloud = WordCloud(background_color=\"white\", repeat=False).generate(wc_city)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.figure(figsize=(10,10)) #inches\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Save wordcloud to django static folder\n",
    "path = os.getcwd() + r\"\\WeWarnYou-dashboard\\apps\\static\\assets\\wc-location.png\"\n",
    "wordcloud.to_file(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdb78f1",
   "metadata": {},
   "source": [
    "## Count of flood-related hashtag against time line graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24490ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split timestamp into date and timestamp\n",
    "timestamp = df[\"created_at\"].str.split(\" \", n = 1, expand = True)\n",
    "df[\"date\"] = pd.to_datetime(timestamp[0])\n",
    "df[\"time\"] = timestamp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c18a9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the tweets by date into new dataframe\n",
    "df_count = df.groupby(df.date.dt.floor('1D')).count()\n",
    "df_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea6702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convention for import of the pyplot interface\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set-up to have matplotlib use its support for notebook inline plots\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Specify how our lines should look\n",
    "ax.plot(df_count.tweet_text, color='tab:blue', label='Count')\n",
    "\n",
    "# Same as above\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Flood-related Tweets')\n",
    "ax.grid(True)\n",
    "ax.legend(loc='upper left');\n",
    "\n",
    "\n",
    "# Save line graph to django static folder\n",
    "path = os.getcwd() + r\"\\WeWarnYou-dashboard\\apps\\static\\assets\\flood-trend.png\"\n",
    "plt.savefig(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c4ae75",
   "metadata": {},
   "source": [
    "## Most mentioned party in tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cf3397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare Malaysia Party, as of Jan 2022\n",
    "\n",
    "df_party = pd.DataFrame([\n",
    "    ['PH', 'DAP'],['PH', 'PKR'],['PH', 'AMANAH'],\n",
    "    ['PN', 'BERSATU'],['PN', 'PAS'],['PN', 'GERAKAN'],\n",
    "    ['BN', 'UMNO'],['BN', 'MCA'],['BN', 'MIS']\n",
    "], columns=['Party','Member'])\n",
    "\n",
    "df_party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ef0032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many times those party were mentioned\n",
    "\n",
    "# Declare empty list\n",
    "count = []\n",
    "\n",
    "for member in df_party['Member']:\n",
    "    \n",
    "    # Create a regex for the party to search for uppercase and lowercase and must have space before and after\n",
    "    # For eg, DAP -> \"\\sDAP|dap\\s\"\n",
    "    reg = \"\\s\" + member + \"|\" + member.lower() + \"\\s\"\n",
    "    s = df['tweet_text'].str.count(reg).sum()\n",
    "    count.append(s)\n",
    "    \n",
    "df_party['Count'] = count\n",
    "df_party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b685b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following nested chart are reference through this site\n",
    "# Ref 1 - https://stackoverflow.com/questions/67210640/how-can-i-draw-a-nested-pie-graph-in-matplotlib-in-python\n",
    "# Ref 2 - https://matplotlib.org/stable/gallery/pie_and_polar_charts/nested_pie.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83d5d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_party_outer = df_party.groupby(['Party']).sum()\n",
    "df_party_outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403bade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_party_inner = df_party.groupby(['Party', 'Member']).sum()\n",
    "\n",
    "df_party_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2558170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inner labels for inner pie chart\n",
    "inner_labels = df_party_inner.index.get_level_values(1)\n",
    "inner_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7710133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define color for pie chart\n",
    "cmap = plt.cm.get_cmap(\"tab20c\")\n",
    "outer_colors = cmap(np.arange(3)*4)\n",
    "inner_colors = cmap([1, 2, 3, 4, 5, 6, 8, 9, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4153572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating autocpt arguments \n",
    "def func(pct, allvalues): \n",
    "    absolute = int(pct / 100.*np.sum(allvalues)) \n",
    "    return \"{:.1f}%\\n({:d})\".format(pct, absolute) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaa8d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(40,20))\n",
    "size = 0.3\n",
    "\n",
    "ax.pie(df_party_outer.values.flatten(), radius=1,\n",
    "       labels=df_party_outer.index,\n",
    "       autopct = lambda pct: func(pct, df_party_outer),\n",
    "       pctdistance = 0.9,\n",
    "       colors=outer_colors,\n",
    "       wedgeprops=dict(width=size, edgecolor='black'))\n",
    "\n",
    "ax.pie(df_party_inner.values.flatten(), radius=1-size, \n",
    "       labels = inner_labels,\n",
    "       autopct = lambda pct: func(pct, df_party_inner),\n",
    "       pctdistance = 0.9,\n",
    "       colors=inner_colors,\n",
    "       labeldistance = 0.4,\n",
    "       rotatelabels = True,\n",
    "       wedgeprops=dict(width=size, edgecolor='black'))\n",
    "\n",
    "# Save pie chart to django static folder\n",
    "path = os.getcwd() + r\"\\WeWarnYou-dashboard\\apps\\static\\assets\\pc-party.png\"\n",
    "\n",
    "plt.savefig(path, bbox_inches=\"tight\")\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5cb50f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
